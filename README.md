# Open Source LLMs List

| Name | by | URL | Demo | Size | Max Token | VQAv2 | GQA | VizWiz | SQA | T-VQA | POPE | MME | MM-Bench | SEED | LLaVA-Bench-Wild | MM-Vet | MMLU | GSM8K | MATH | BIG-Bench-Hard | HumanEval | Natural2Code | DROP | Hellaswag | WMT23 | WinoGrande | AI2 Reasoning Challenge (ARC) |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| LLaVa-v1.5-13B | haotian-liu | https://github.com/haotian-liu/LLaVA | https://llava.hliu.cc/ | 13B | | 78.5 | 62.0 | 50.0 | 66.8 | 58.2 | 85.9 | 1510.7 | 64.3 | 58.3 | 58.6 | 65.4 | 31.1 |
| LLaVa-v1.5-7B | haotian-liu | https://github.com/haotian-liu/LLaVA | https://llava.hliu.cc/ | 7B | | 80.0 | 63.3 | 53.6 | 71.6 | 61.3 | 85.9 | 1531.3 | 67.7 | 63.6 | 61.6 | 72.5 | 36.1 |
| Gemini Ultra | Google | https://blog.google/technology/ai/google-gemini-ai/ , https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf | No Demo is available | 10T? |
| Gemini Pro | Google | https://blog.google/technology/ai/google-gemini-ai/ , https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf | Through Google API |  1.56T? |
| Gemini Nano-1 | Google | https://blog.google/technology/ai/google-gemini-ai/ , https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf | Through Pixel | 1.8B |
| Gemini Nano-2 | Google | https://blog.google/technology/ai/google-gemini-ai/ , https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf | Through Pixel | 3.25B |
| GPT-4 | OpenAI | https://cdn.openai.com/papers/gpt-4.pdf , https://chat.openai.com | https://chat.openai.com | Unknown | 8192, 32768 |  |  |  |  |  |  |  |  |  |  |  | 86.4 5-shot |  |  |  | 67.0% 0-shot |  | 80.9 3-shot | 95.3 10-shot |  | 87.5 5-shot | 96.3 25-shot |
| GPT-3.5 | OpenAI | https://chat.openai.com | https://chat.openai.com | Unknown? | Max Token | VQAv2 | GQA | VizWiz | SQA | T-VQA | POPE | MME | MM-Bench | SEED | LLaVA-Bench-Wild | MM-Vet | MMLU | GSM8K | MATH | BIG-Bench-Hard | HumanEval | Natural2Code | DROP | Hellaswag | WMT23 | WinoGrande | AI2 Reasoning Challenge (ARC) |
| GPT-3.5-Turbo | OpenAI | https://chat.openai.com | https://chat.openai.com | Unknown? | Max Token | VQAv2 | GQA | VizWiz | SQA | T-VQA | POPE | MME | MM-Bench | SEED | LLaVA-Bench-Wild | MM-Vet | MMLU | GSM8K | MATH | BIG-Bench-Hard | HumanEval | Natural2Code | DROP | Hellaswag | WMT23 | WinoGrande | AI2 Reasoning Challenge (ARC) |
| PaLM 2-L | Google | 
| Claude 2 | Anthropic |
| INSTRUCT-GPT |
| GROK | 
| LLaMa 2 | Meta |
