# Open Source LLMs List

> [!NOTE]
> Name that "*" is added is closed source, not open source.
> 
> Value that "?" is added might not be accurate, or might be myth (hallucination). 

| Name | by | URL | Demo | Size | Max Token | VQAv2 | GQA | VizWiz | SQA | T-VQA | POPE | MME | MM-Bench | SEED | LLaVA-Bench-Wild | MM-Vet | MMLU | GSM8K | MATH | BIG-Bench-Hard | HumanEval | Natural2Code | DROP | Hellaswag | WMT23 | WinoGrande | AI2 Reasoning Challenge (ARC) |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| LLaVa-v1.5-13B | haotian-liu | https://github.com/haotian-liu/LLaVA | https://llava.hliu.cc/ | 13B | | 78.5 | 62.0 | 50.0 | 66.8 | 58.2 | 85.9 | 1510.7 | 64.3 | 58.3 | 58.6 | 65.4 | 31.1 |
| LLaVa-v1.5-7B | haotian-liu | https://github.com/haotian-liu/LLaVA |  | 7B | | 80.0 | 63.3 | 53.6 | 71.6 | 61.3 | 85.9 | 1531.3 | 67.7 | 63.6 | 61.6 | 72.5 | 36.1 |
| *Gemini Ultra | Google | https://blog.google/technology/ai/google-gemini-ai/ , https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf | No Demo is available | 10T? |
| *Gemini Pro | Google | https://blog.google/technology/ai/google-gemini-ai/ , https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf | Through Google API |  1.56T? |
| *Gemini Nano-1 | Google | https://blog.google/technology/ai/google-gemini-ai/ , https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf | Via Google Pixel 8 | 1.8B |
| *Gemini Nano-2 | Google | https://blog.google/technology/ai/google-gemini-ai/ , https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf | Via Google Pixel 8 | 3.25B |
| *GPT-4 | OpenAI | https://cdn.openai.com/papers/gpt-4.pdf , https://chat.openai.com | https://chat.openai.com | Unknown | 8192, 32768 |  |  |  |  |  |  |  |  |  |  |  | 86.4 5-shot |  |  |  | 67.0% 0-shot |  | 80.9 3-shot | 95.3 10-shot |  | 87.5 5-shot | 96.3 25-shot |
| *GPT-3.5 | OpenAI | https://chat.openai.com | https://chat.openai.com | Unknown? | Max Token | VQAv2 | GQA | VizWiz | SQA | T-VQA | POPE | MME | MM-Bench | SEED | LLaVA-Bench-Wild | MM-Vet | MMLU | GSM8K | MATH | BIG-Bench-Hard | HumanEval | Natural2Code | DROP | Hellaswag | WMT23 | WinoGrande | AI2 Reasoning Challenge (ARC) |
| *GPT-3.5-Turbo | OpenAI | https://chat.openai.com | https://chat.openai.com | Unknown? | Max Token | VQAv2 | GQA | VizWiz | SQA | T-VQA | POPE | MME | MM-Bench | SEED | LLaVA-Bench-Wild | MM-Vet | MMLU | GSM8K | MATH | BIG-Bench-Hard | HumanEval | Natural2Code | DROP | Hellaswag | WMT23 | WinoGrande | AI2 Reasoning Challenge (ARC) |
| *PaLM 2-L | Google | https://ai.google/discover/palm2/ |  
| *Claude 2 | Anthropic | https://www.anthropic.com/index/claude-2 |
| *GROK | X AI | https://grok.x.ai/ | Unavailable |
| LLaMa-2-70B | Meta | https://ai.meta.com/llama/ | https://sdk.vercel.ai/ | 70B |
| LLaMa-2-13B | Meta | https://ai.meta.com/llama/ | https://sdk.vercel.ai/ | 13B |
| LLaMa-2-7B | Meta | https://ai.meta.com/llama/ | https://sdk.vercel.ai/ | 7B |
